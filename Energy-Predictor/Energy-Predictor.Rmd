---
title: "Energy Predictor"
author: "Zhongyi Sheng"
date: "4/20/2020"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
installIfAbsentAndLoad <- function(neededVector) {
  for(thispackage in neededVector) {
    if( ! require(thispackage, character.only = T) )
    { install.packages(thispackage)}
    require(thispackage, character.only = T)
  }
}

needed <- c('tidyverse','repr','lubridate','gbm','ggplot2','xgboost','Ecdat','reshape2','ggcorrplot','car')  
installIfAbsentAndLoad(needed)
options(tibble.width = Inf)
options(warn=-1)
```

## Competition Objective

In this competition, youâ€™ll develop accurate models of metered building energy usage in the following areas: chilled water, electric, hot water, and steam meters. The data comes from over 1,000 buildings over a three-year timeframe. With better estimates of these energy-saving investments, large scale investors and financial institutions will be more inclined to invest in this area to enable progress in building efficiencies.

### How we arrive at our model:

First we dive into the background of the competition and acknowledge the assumptions of ou project. Then we take the following steps to write our notebook.

#### 1)Load Data

#### 2)Preprocessing

#### 3)EDA

#### 4)Build and train model

#### 5)Outcome evaluation

##Load data

### Read files
```{r read files}
dpath <- "./"
train <- read.csv(paste(dpath, "train.csv", sep=""),row.names = NULL)
building<-read.csv('building_metadata.csv',row.names = NULL)
weather_train<-read.csv('weather_train.csv',row.names = NULL)
```

### Joining the data table

```{r }
train<-train%>%
  left_join(building,by='building_id')%>%
  left_join(weather_train,by=c('site_id',"timestamp"))

```
### Take a glimpse of the data structure

```{r }

head(weather_train,5)
```

## Preprocessing

### Make new variables
```{r }
#Transform the data to days in a week(1,2,3,4,5,6,7)
train$wday=wday(train$timestamp)
#Identify whether it's workday or not
train$workday=ifelse(train$wday %in% c(1,2,3,4,5),1,0)
#Take out the month information
train$month=month(train$timestamp)
#Normalize the target so that it's not scaled
train$meter_reading=log1p(train$meter_reading)
```

### Feature selection

```{r }
#Select columns as input variables
names_selected=c("building_id","site_id","meter","primary_use","square_feet","air_temperature","cloud_coverage","wind_direction","wind_speed", "month","workday","meter_reading")
#Get the new dataset
train.new=train[names_selected]
```
### Convert categorical variable to numeric

```{r }
#Transfrom "primary_use" variable to numerirical data
train.new$primary_use=as.integer(as.factor(train.new$primary_use))

```

### Fill in missing data

Because the missing data portion is small, we could just use the avaerage to replace the NAs.
```{r }
#Deal with air temperature missing data
train.new$air_temperature[is.na(train.new$air_temperature)] <- mean(train.new$air_temperature, na.rm = TRUE)
#Deal with cloud coverage mmissing data
train.new$cloud_coverage[is.na(train.new$cloud_coverage)] <- mean(train.new$cloud_coverage, na.rm = TRUE)
#Deal with wind direction missing data
train.new$wind_direction[is.na(train.new$wind_direction)] <- mean(train.new$wind_direction, na.rm = TRUE)
```

## EDA
### Correlations

```{r cor,echo=FALSE}
ggcorrplot(cor(train.new), type = "lower", lab = TRUE,
           title = "Correlation Matrix for All Features")
```

Potentially significant correlations: square feet correlated with meter reading at 0.37, wind direction with wind speed at 0.42, wind speed with cloud coverage at 0.18.
Unsurprisingly, building ID and site ID are highly correlated because they are linked.
Site and building ID are each somewhat correlated with temperature and cloud coverage (due to location)


### Evaluate multicollinearity between predictors
```{r vif,echo=FALSE}
# Take a subset of data to reduce running time
train.new.site1=train.new[train.new$site_id==1,]
# remove meter_reading before checking for VIF
simple.regression <- lm(meter_reading~.-site_id, data = train.new.site1)
vif(simple.regression) 
```

Unsurpisingly, the VIF of building and site ID are both extremely high given how we know they are completely linked and 98% correlated with one another.
The rest of the predictors appear to be okay, with VIFs at ~1 even when building and site ID are removed from the model.

## Build and train model

### XGBoost model

XGBoost is a ensemble method for machine learning which allows parrallel runnning. XGBoost is a powerful tool that has low bias.
We selected XGBoost for our model because the size of our data, and the flexiblity XGBoost could achieve.
For our problem, because the data is too large (378MB), and data from different sites may vary.
We choose to train a seperate model on each site using XGBoost.
```{r }
#Extract data from site 1
train.new.site1=train.new[train.new$site_id==1,]
#Get number of rows for site 1
n=nrow(train.new.site1)
#Sample the data into training and test set
train.index=sample(seq(1,n),n*0.8,replace = F)
#Transfrom the training data into matrix before fitting into XGBoost model
xgb.data.train <- xgb.DMatrix(as.matrix(train.new.site1[train.index, colnames(train.new.site1) != 'meter_reading']), label = train.new.site1$meter_reading[train.index])
#Transfrom the test data into matrix before fitting into XGBoost model
xgb.data.test <- xgb.DMatrix(as.matrix(train.new.site1[-train.index, colnames(train.new) != "meter_readings"]), label = train.new.site1$meter_reading[-train.index])

```

### Parameter Tuning

We included 3 hyperparameters in the tuning process.
```{r }
# = eta candidates = #
eta=c(0.05,0.1,0.5)
# = max_depth candidates = #
md=c(6,10,12)
# = sub_sample candidates = #
ss=c(0.25,0.5,0.75,1)
```

### eta

```{r }
#Define a vector to store rmse data
test_rmse=c()
#For each value of eta, the model will produce its test rmse over each round of training
for(i in 1:length(eta)){
  #Define parameters in the model
  params=list(booster = "gbtree",nthread = 4, objective = "reg:squarederror",
              eta = eta[i], gamma=0, max_depth=10, min_child_weight=1, 
              subsample=1, colsample_bytree=0.85)
  #Using cross validation to find how the rmse changes over time
  xgbcv <- xgb.cv( params = params, data = xgb.data.train , nrounds = 500, nfold = 3, showsd = T, stratified = T, print_every_n = 100, maximize = F)
  #Get test rmse data
  test_rmse[i] = xgbcv$evaluation_log[,4]
  
}
#Transfrom test_rmse of each value of eta into a dataframe
test_rmse = data.frame(iter=1:500,test_rmse)
#Name the test_rmse dataframe columns

colnames(test_rmse) =  c('iter',eta)
#Reshape the test_rmse for plotting
test_rmse = melt(test_rmse, id.vars = "iter")

```
Plot how each test rmse changes over training iterations
```{r eta, echo=FALSE}

ggplot(data = test_rmse) + geom_line(aes(x = iter, y = value, color = variable))

```
The best eta is 0.5.

### Max depth

```{r }
#Define a vector to store rmse data
test_rmse=c()
#For each value of max depth, the model will produce its test rmse over each round of training

for(i in 1:length(md)){
   #Define parameters in the model

  params=list(booster = "gbtree",nthread = 4, objective = "reg:squarederror",
              eta = 0.5, gamma=0, max_depth=md[i], min_child_weight=1, 
              subsample=1, colsample_bytree=0.85)
  #Using cross validation to find how the rmse changes over time
  xgbcv <- xgb.cv( params = params, data = xgb.data.train , nrounds = 500, nfold = 3, showsd = T, stratified = T, print_every_n = 100, maximize = F)
  #Get test rmse data
  test_rmse[i] = xgbcv$evaluation_log[,4]
  
}
#Transfrom test_rmse of each value of eta into a dataframe

test_rmse = data.frame(iter=1:500,test_rmse)
#Name the test_rmse dataframe columns

colnames(test_rmse) =  c('iter',md)
#Reshape the test_rmse for plotting

test_rmse = melt(test_rmse, id.vars = "iter")

```

Plot how each test rmse changes over training iterations

```{r md, echo=FALSE}
ggplot(data = test_rmse) + geom_line(aes(x = iter, y = value, color = variable))

```

The best max depth 6.

### Subsample candidates

```{r }
#Define a vector to store rmse data

test_rmse=c()
#For each value of subsample size, the model will produce its test rmse over each round of training

for(i in 1:length(ss)){
     #Define parameters in the model

  params=list(booster = "gbtree",nthread = 4, objective = "reg:squarederror",
              eta = 0.5, gamma=0, max_depth=6, min_child_weight=1, 
              subsample=ss[i], colsample_bytree=0.85)
    #Using cross validation to find how the rmse changes over time

  xgbcv <- xgb.cv( params = params, data = xgb.data.train , nrounds = 500, nfold = 3, showsd = T, stratified = T, print_every_n = 100, maximize = F)
    #Get test rmse data

  test_rmse[i] = xgbcv$evaluation_log[,4]
  
}
#Transfrom test_rmse of each value of subsample into a dataframe

test_rmse = data.frame(iter=1:500,test_rmse)
#Name the test_rmse dataframe columns

colnames(test_rmse) =  c('iter',ss)
#Reshape the test_rmse for plotting

test_rmse = melt(test_rmse, id.vars = "iter")

```
Plot how each test rmse changes over training iterations

```{r ss, echo=FALSE}
ggplot(data = test_rmse) + geom_line(aes(x = iter, y = value, color = variable))

```

The best subsample size is 1.

### Fit best model

```{r }
#Define parameters using the best fit result above
params=list(booster = "gbtree",nthread = 4, objective = "reg:squarederror",
            eta = 0.5 , gamma=0, max_depth=6, min_child_weight=1, 
            subsample=1, colsample_bytree=0.85)
#Train the data using hyperparameter values
xgb1 <- xgb.train (params = params, data = xgb.data.train, nrounds = 500, watchlist = list(val=xgb.data.test,train=xgb.data.train), print.every.n = 100, 
                   early.stop.round = 10, maximize = F , eval_metric = "rmse")
#See how the model performs on the test data set
xgb1$evaluation_log[490:500]
```

## Outcome evaluation: Feature importance

```{r }
#Get the feature importance in the final model
mat <- xgb.importance (feature_names = colnames(train.new.site1),model = xgb1)

```
```{r outcome, echo=FALSE}
xgb.plot.importance (importance_matrix = mat) 
```

In the plot, we could see that the building_id, meter, and sqaure_feet are most important features in our model, which makes sense.
Different buildings have different energy consumptions. Based on the type of meter, the energy consumption will vary. And bigger house with more square feet will use more energy.

Further we implemented our model in the test dataset on Kaggle which have no labels.
